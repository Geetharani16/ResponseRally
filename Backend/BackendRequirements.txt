# Backend Requirements for ResponseRally Frontend

## API Endpoints and Expected Return Data

### Session Management Endpoints

#### 1. Create Session
- **Endpoint**: `POST /api/v1/session`
- **Description**: Creates a new session for AI comparisons
- **Request Body**: None required
- **Expected Response**: Session object with initial state
- **Response Format**:
```
{
  "id": "string (UUID)",
  "conversationHistory": [],
  "currentPrompt": "",
  "currentResponses": [],
  "isProcessing": false,
  "selectedResponseId": null,
  "enabledProviders": ["gpt", "llama", "mistral", "gemini", "copilot", "deepseek", "ollama"],
  "createdAt": "date string",
  "updatedAt": "date string"
}
```

#### 2. Get Session
- **Endpoint**: `GET /api/v1/session/:sessionId`
- **Description**: Retrieves session details by session ID
- **Request Parameters**: sessionId (in URL path)
- **Expected Response**: Session object with current state
- **Response Format**:
```
{
  "id": "string (UUID)",
  "conversationHistory": [ConversationTurn[]],
  "currentPrompt": "string",
  "currentResponses": [ProviderResponse[]],
  "isProcessing": boolean,
  "selectedResponseId": "string or null",
  "enabledProviders": ["providerId"],
  "createdAt": "date string",
  "updatedAt": "date string"
}
```

#### 3. Reset Session
- **Endpoint**: `POST /api/v1/session/:sessionId/reset`
- **Description**: Resets a session to initial state while preserving the session ID
- **Request Parameters**: sessionId (in URL path)
- **Request Body**: None required
- **Expected Response**: New session object with same ID
- **Response Format**:
```
{
  "id": "string (UUID)",
  "conversationHistory": [],
  "currentPrompt": "",
  "currentResponses": [],
  "isProcessing": false,
  "selectedResponseId": null,
  "enabledProviders": ["gpt", "llama", "mistral", "gemini", "copilot", "deepseek", "ollama"],
  "createdAt": "date string",
  "updatedAt": "date string"
}
```

### Prompt Processing Endpoints

#### 4. Submit Prompt
- **Endpoint**: `POST /api/v1/prompt`
- **Description**: Submit a prompt to multiple AI providers for parallel processing
- **Request Body**:
```
{
  "sessionId": "string (UUID)",
  "prompt": "string (user input)",
  "providers": ["providerId"] (optional, if not provided use enabledProviders),
  "context": [ConversationTurn[]] (optional, conversation history)
}
```
- **Expected Response**: Updated session with initial responses and processing state
- **Response Format**:
```
{
  "id": "string (UUID)",
  "conversationHistory": [ConversationTurn[]],
  "currentPrompt": "string",
  "currentResponses": [ProviderResponse[]],
  "isProcessing": true,
  "selectedResponseId": null,
  "enabledProviders": ["providerId"],
  "createdAt": "date string",
  "updatedAt": "date string"
}
```
- **Real-time Updates**: Backend should provide streaming updates for response progress via WebSocket or Server-Sent Events (SSE) as responses are received from different providers

### Response Management Endpoints

#### 5. Select Best Response
- **Endpoint**: `POST /api/v1/session/:sessionId/select-response`
- **Description**: Mark a specific response as the "best" selection, add to conversation history
- **Request Parameters**: sessionId (in URL path)
- **Request Body**:
```
{
  "responseId": "string (UUID of selected response)"
}
```
- **Expected Response**: Updated session with conversation history and cleared current responses
- **Response Format**:
```
{
  "id": "string (UUID)",
  "conversationHistory": [ConversationTurn[] with new turn added],
  "currentPrompt": "",
  "currentResponses": [],
  "isProcessing": false,
  "selectedResponseId": "string (UUID of selected response)",
  "enabledProviders": ["providerId"],
  "createdAt": "date string",
  "updatedAt": "date string"
}
```

#### 6. Toggle Provider
- **Endpoint**: `POST /api/v1/session/:sessionId/toggle-provider`
- **Description**: Enable or disable a specific AI provider
- **Request Parameters**: sessionId (in URL path)
- **Request Body**:
```
{
  "providerId": "string (provider identifier)"
}
```
- **Expected Response**: Updated session with modified enabled providers list
- **Response Format**:
```
{
  "id": "string (UUID)",
  "conversationHistory": [ConversationTurn[]],
  "currentPrompt": "string",
  "currentResponses": [ProviderResponse[]],
  "isProcessing": boolean,
  "selectedResponseId": "string or null",
  "enabledProviders": ["providerId"] (with provider toggled),
  "createdAt": "date string",
  "updatedAt": "date string"
}
```

#### 7. Retry Provider
- **Endpoint**: `POST /api/v1/session/:sessionId/retry-provider`
- **Description**: Retry a failed provider response
- **Request Parameters**: sessionId (in URL path)
- **Request Body**:
```
{
  "providerId": "string (provider identifier)"
}
```
- **Expected Response**: Updated session with provider response status reset to pending
- **Response Format**:
```
{
  "id": "string (UUID)",
  "conversationHistory": [ConversationTurn[]],
  "currentPrompt": "string",
  "currentResponses": [ProviderResponse[] with specified provider reset to pending],
  "isProcessing": boolean,
  "selectedResponseId": "string or null",
  "enabledProviders": ["providerId"],
  "createdAt": "date string",
  "updatedAt": "date string"
}
```

### Ollama-Specific Endpoints

#### 8. Ollama Health Check
- **Endpoint**: `GET /api/v1/ollama/health`
- **Description**: Check if Ollama service is available
- **Request Body**: None required
- **Expected Response**: Status of Ollama connection
- **Response Format**:
```
{
  "status": "Ollama is running" or "Ollama not available",
  "models": [model list] (if available)
}
```

#### 9. Ollama Process
- **Endpoint**: `POST /api/v1/ollama/process`
- **Description**: Process a prompt specifically for Ollama
- **Request Body**:
```
{
  "sessionId": "string (UUID)",
  "prompt": "string (user input)",
  "context": [ConversationTurn[]] (optional, conversation history)
}
```
- **Expected Response**: Response from Ollama provider
- **Response Format**:
```
{
  "response": {
    "id": "string (UUID)",
    "provider": "ollama",
    "prompt": "string",
    "response": "string (AI response)",
    "status": "request status",
    "metrics": {
      "latencyMs": "number or null",
      "tokenCount": "number or null",
      "responseLength": "number",
      "firstTokenLatencyMs": "number or null",
      "tokensPerSecond": "number or null"
    },
    "retryCount": "number",
    "errorMessage": "string or null",
    "streamingProgress": "number (0-100)",
    "timestamp": "number (timestamp)",
    "isStreaming": "boolean"
  }
}
```

### Health Check Endpoint

#### 10. Server Health Check
- **Endpoint**: `GET /health`
- **Description**: Check server health status
- **Request Body**: None required
- **Expected Response**: Server status information
- **Response Format**:
```
{
  "status": "OK",
  "timestamp": "date string"
}
```

## Data Structures

### ProviderResponse
```
{
  "id": "string (UUID)",
  "provider": "gpt|llama|mistral|gemini|copilot|deepseek|ollama",
  "prompt": "string",
  "response": "string",
  "status": "idle|pending|streaming|success|error|timeout|rate-limited",
  "metrics": {
    "latencyMs": "number or null",
    "tokenCount": "number or null",
    "responseLength": "number",
    "firstTokenLatencyMs": "number or null",
    "tokensPerSecond": "number or null"
  },
  "retryCount": "number",
  "errorMessage": "string or null",
  "streamingProgress": "number (0-100)",
  "timestamp": "number (timestamp)",
  "isStreaming": "boolean"
}
```

### ConversationTurn
```
{
  "id": "string (UUID)",
  "userPrompt": "string",
  "selectedResponse": "ProviderResponse or null",
  "allResponses": "[ProviderResponse[]]",
  "timestamp": "number (timestamp)"
}
```

### SessionState
```
{
  "id": "string (UUID)",
  "conversationHistory": "[ConversationTurn[]]",
  "currentPrompt": "string",
  "currentResponses": "[ProviderResponse[]]",
  "isProcessing": "boolean",
  "selectedResponseId": "string or null",
  "enabledProviders": "["providerId"]"
}
```